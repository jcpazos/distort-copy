#!/usr/bin/env python2

#
# Provide a path to a folder generated by 'vmctl evalcollect'
# and this tool will print statistics about the run
#

import sys
import os, os.path

def log(*args):
    sys.stderr.write(" ".join([ str(x) for x in args ]) + "\n")


def process_logs(dpath, opts):
    opts_secs = opts.minutes * 60

    contdir = os.path.join(dpath, "cont")
    if not os.path.exists(contdir):
        raise Exception("directory " + contdir + " does not exist.")

    netstats = []
    with open(os.path.join(contdir, "netstats.log"), "r") as netfd:
        for line in netfd:
            line = line.strip()
            if not line:
                continue
            ns = {}
            nums = [ int(x, 10) for x in line.split(" ") ]
            ns = {
                'ts': nums[0],
                'rxbytes': nums[1],
                'rxpackets': nums[2],
                'txbytes': nums[7],
                'txpackets': nums[8]
            }
            netstats.append(ns)

    netstats_timespan = netstats[-1]['ts'] - netstats[0]['ts']
    log("netstats time recorded: %d seconds. (%4.2f hours)" % (netstats_timespan, netstats_timespan / 3600.0));

    logstats = []
    evalstart_found = False

    with open(os.path.join(contdir, "google-dir", "chrome_debug.log"), "r") as debugfd:
        for line in debugfd:
            line = line.strip()
            if not line:
                continue
            words = line.split(" ")
            if not ":CONSOLE(" in words[0]:
                continue
            #[650:650:0517/095259.187793:INFO:CONSOLE(589)] "[UI.log] 1495014779.186 __EVALSTART__ twx171f 0 900000", source: chrome-extension://ohmpdiobkemenjbaamoeeenbniglebli/ui.js (589)

            # keep contents of console.log()
            words = words[1:-3]
            # remove " and ",
            words[0] = words[0][1:]
            words[-1] = words[-1][:-2]

            if "__EVALSTART__" in words:
                log("eval config: " + " ".join(words))
                evalstart_found = True
                continue

            if words[0] != "[stats]":
                continue
            logstat = {
                "ts": float(words[1])
            }
            for i in range(2, len(words), 2):
                tok = words[i]
                if tok.endswith(":"):
                    tok = tok[:-1]
                try:
                    intval = int(words[i+1], 10)
                    logstat[tok] = intval
                except Exception, exc:
                    logstat[tok] = words[i+1]
            logstats.append(logstat)

    first_ts = max(netstats[0]['ts'], logstats[0]['ts'])
    last_ts  = min(netstats[-1]['ts'], logstats[-1]['ts'])

    if not evalstart_found:
        log("WARNING: COULD NOT FIND EVALSTART MARKER")

    log("common timespan recorded %s seconds (%4.2f hours)" % (last_ts - first_ts, (last_ts - first_ts) / 3600))

    if last_ts - first_ts < opts_secs:
        log("not enough data: %s < %s" % (last_ts - first_ts, opts_secs))
        sys.exit(2)

    start_ts = last_ts - opts_secs
    log("selecting last %s seconds: %s to %s" % (opts_secs, start_ts, last_ts))

    # pick the log events that are between [start_ts, last_ts]
    netstats_tail = filter(lambda x: x['ts'] >= start_ts and x['ts'] <= last_ts, netstats)
    logstats_tail = filter(lambda x: x['ts'] >= start_ts and x['ts'] <= last_ts, logstats)

    log("netstats_start: ", netstats_tail[0])
    log("netstats_end: ",   netstats_tail[-1])
    log("browser_start:",   logstats_tail[0])
    log("browser_end:",     logstats_tail[-1])

    def do_diff(arr, fieldname):
        return arr[-1][fieldname] - arr[0][fieldname]

    # print header
    print "%(time_sec)-8s %(time_min)-8s %(net_rx)-8s %(day_rxMB)-8s %(net_tx)-8s %(day_txMB)-8s %(t_rx)-8s %(t_tx)-8s %(in_drop)-8s %(in_proc)-8s" % {
        "time_sec": "delta_t",
        "time_min": "time_min",
        "net_rx": "net_rx",
        "day_rxMB": "day_rxMB",
        "net_tx": "net_tx",
        "day_txMB": "day_txMB",
        "t_rx": "t_rx",
        "t_tx": "t_tx",
        "in_drop": "in_drop",
        "in_proc": "in_proc"}

    delta_t = do_diff(netstats_tail, "ts")
    delta_rx = do_diff(netstats_tail, "rxbytes")
    delta_tx = do_diff(netstats_tail, "txbytes")
    s_per_day = 3600 * 24.0
    B_per_MB = 1024 * 1024
    day_rxMB = (s_per_day * delta_rx / delta_t) / (B_per_MB)
    day_txMB = (s_per_day * delta_tx / delta_t) / (B_per_MB)

    # print values
    print "%(time_sec)-8s %(time_min)-8s %(net_rx)-8s %(day_rxMB)-8s %(net_tx)-8s %(day_txMB)-8s %(t_rx)-8s %(t_tx)-8s %(in_drop)-8s %(in_proc)-8s" % {
        "time_sec": delta_t,
        "time_min": int(delta_t / 60),
        "net_rx":   delta_rx,
        "day_rxMB": "%.3f" % (day_rxMB,),
        "net_tx":   delta_tx,
        "day_txMB": "%.3f" % (day_txMB,),
        "t_rx":     do_diff(logstats_tail, "twitter.rx"),
        "t_tx":     do_diff(logstats_tail, "twitter.tx"),
        "in_drop":  do_diff(logstats_tail, "inbox.ndrop"),
        "in_proc":  do_diff(logstats_tail, "inbox.nproc")
    }

def main():
    import argparse
    parser = argparse.ArgumentParser(description='chrome_log measure')

    parser.add_argument('--minutes', metavar="M", type=int,
                        help="how many of the last minutes to cover",
                        default=60)
    parser.add_argument('path', metavar='PATH', type=str,
                        help='path for the output folder')
    args = parser.parse_args()

    process_logs(args.path, args)
    return 0

if __name__ == "__main__":
    import sys
    sys.exit(main())
